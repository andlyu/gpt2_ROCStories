{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9ddb6752ce88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpt23/lib/python3.8/site-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \"\"\"\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Dataset/0OYkPK', sep=\",\", header=None)\n",
    "data.columns = data.iloc[0]\n",
    "data = data[1:]\n",
    "data['full'] = data['sentence1']+ \" \" + data['sentence2']+ \" \" + data['sentence3']+ \" \" + data['sentence4']+ \" \" + data['sentence5']\n",
    "data['input'] = data['sentence1']+ \" \" + data['sentence2']+ \" \" + data['sentence3']+ \" \" + data['sentence4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model = GPT2Model.from_pretrained('gpt2',pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:1\n",
      "DataParallel()\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)\n",
    "a = torch.Tensor(5,3)\n",
    "dp_m = torch.nn.DataParallel(a)\n",
    "dp_m.to(device)\n",
    "print(dp_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "#outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (6): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (7): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (8): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (9): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (10): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (11): GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my dog is cute and icky. I'm not sure if she's a good dog\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "#device_map = {0: [0, 1, 2],\n",
    "#            1: [3, 4,5],\n",
    "#            2: [6, 7, 8],\n",
    "#            3: [9,10,11]}\n",
    "#model = torch.nn.DataParallel(model) # Splits the model across several devices\n",
    "model.to(device)\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute and \", return_tensors=\"pt\")\n",
    "inputs.to(device)\n",
    "generation_output = model.generate(**inputs, return_dict_in_generate=True, output_scores=True)\n",
    "output = tokenizer.decode(generation_output['sequences'][0])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(100):\n",
    "#    #tokenizer.decode(generation_output[0])\n",
    "#\n",
    "#    inputs = tokenizer(\"Hello, my dog is cute and \", return_tensors=\"pt\")\n",
    "#    inputs.to(device)\n",
    "#    generation_output = model.generate(**inputs, return_dict_in_generate=True, output_scores=True)\n",
    "#    output = tokenizer.decode(generation_output['sequences'][0])\n",
    "#    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  1%|          | 1/100 [00:00<01:15,  1.31it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 0 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "David noticed he had put on a lot of weight recently. He examined his habits to try and figure out the reason. He realized he'd been eating too much fast food lately. He stopped going to burger places and started a vegetarian diet.\n",
      "Expected:\n",
      "After a few weeks, he started to feel much better.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm not a big fan of fast food,\" he said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:01<01:24,  1.16it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 1 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Tom had a very short temper. One day a guest made him very angry. He punched a hole in the wall of his house. Tom's guest became afraid and left quickly.\n",
      "Expected:\n",
      "Tom sat on his couch filled with regret about his actions.\n",
      "Output:\n",
      "\n",
      "\n",
      "The next day, Tom was in the hospital.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:02<01:16,  1.27it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 2 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Marcus needed clothing for a business casual event. All of his clothes were either too formal or too casual. He decided to buy a pair of khakis. The pair he bought fit him perfectly.\n",
      "Expected:\n",
      "Marcus was happy to have the right clothes for the event.\n",
      "Output:\n",
      " He was very happy with the fit of the khakis.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:03<01:08,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 3 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Bobby thought Bill should buy a trailer and haul it with his car. Bill thought a truck would be better for what he needed. Bobby pointed out two vehicles were much more expensive. Bill was set in his ways with conventional thinking.\n",
      "Expected:\n",
      "He ended up buying the truck he wanted despite Bobby's advice.\n",
      "Output:\n",
      " He was going to buy a trailer and haul it with his car.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:03<01:01,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 4 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "John was a pastor with a very bad memory. He tried to memorize his sermons many days in advance but to no avail. He decided to learn to sing to overcome his handicap. He then made all his sermons into music and sang them on Sundays.\n",
      "Expected:\n",
      "His congregation was delighted and so was he.\n",
      "Output:\n",
      " He was a good teacher and a good friend.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:04<00:58,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 5 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Melody's parents surprised her with a trip to the big aquarium. Melody took a nap during the two hour car ride to the aquarium. When they arrived, Melody was energetic and excited. At the aquarium Melody saw sharks, tropical fish and many others.\n",
      "Expected:\n",
      "After five hours at the aquarium, Melody and her family drove home.\n",
      "Output:\n",
      " She was also surprised to see a large fish.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:04<00:59,  1.57it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 6 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "The math teacher announced a pop quiz as class began. While some students complained, he began passing out the quiz. I took out my pencil and began to work. About 5 minutes later, I finished.\n",
      "Expected:\n",
      "I stood up feeling confident and turned it in.\n",
      "Output:\n",
      "\n",
      "\n",
      "I was so excited.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:05<01:01,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 7 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "My first girlfriend i met on the internet. She lives about 4 hours away from me. Finally after 2 years we met each other. She stayed with me for a week or two.\n",
      "Expected:\n",
      "We decided we couldn't be apart so she moved in with me.\n",
      "Output:\n",
      " She was very nice and very nice.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:05<00:55,  1.65it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 8 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "I got Charlie Horse when I was four years old. He's a brown stuffed horse, and at 35 I still sleep with him at night. He was my best friend, and always laid at the head of my bed. I laid him next to me, smelling his soft fur every night.\n",
      "Expected:\n",
      "I liked to listen to my radio as I fell asleep cuddling him.\n",
      "Output:\n",
      " I was so happy when he was gone.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:06<00:58,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 9 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Laura loved corn. So she decided to grow some in her backyard. The whole process of growing them made her very excited. But she realized that they required too much water.\n",
      "Expected:\n",
      "So Laura quickly abandoned her corn garden idea.\n",
      "Output:\n",
      " So she decided to grow them in a greenhouse.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:07<00:57,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 10 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Andy was invited to a Halloween party. Andy figured that for dramatic effect, he should color his hair. Since Andy's costume was green, Andy decided on that color. After the stylist finished the coloring, Andy regretted it.\n",
      "Expected:\n",
      "Andy was disappointed with his new, bold, green hair color.\n",
      "Output:\n",
      " He decided to go to the bathroom and wash his hair.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:08<01:02,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 11 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Luke was playing hockey at school. The game was tied and almost over. Then Luke made the winning shot! Everybody cheered!\n",
      "Expected:\n",
      "Luke was so proud of himself!\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was like, 'Oh my God, that's a great shot!' \" said Luke.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:08<01:01,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 12 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Robbie was competing in a cross country meet. He was halfway through when his leg cramped up. Robbie wasn't sure he could go on. He stopped for a minute and stretched his bad leg.\n",
      "Expected:\n",
      "Robbie began to run again and finished the race in second place.\n",
      "Output:\n",
      " He was so tired he couldn't even walk.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:09<00:57,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 13 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Jude was very excited about his college graduation ceremony. On the way to the arena, he got stuck in traffic. He only had an hour before the ceremony started. He thought he wasn't going to be able to make it in time.\n",
      "Expected:\n",
      "Luckily, the traffic cleared up in time for him to get to the ceremony.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm so excited,\" he said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:10<00:57,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 14 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Beth sent a letter to Santa Claus. She received a letter back in the mail. Beth did not think that it sounded like the real Santa. She sent another letter calling that Santa a fake.\n",
      "Expected:\n",
      "She did not receive another letter back in the mail.\n",
      "Output:\n",
      "\n",
      "\n",
      "Santa Claus was not a real Santa.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:10<00:57,  1.45it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 15 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Our granddaughter Anna is very fussy about her clothes. She is only two, but wants to pick her outfits. Today her mom wanted Anna to wear a dress. Anna started crying.\n",
      "Expected:\n",
      "They let her wear a t-shirt and shorts instead.\n",
      "Output:\n",
      " She was so upset.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:11<00:56,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 16 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Jake needed a ride to the store. His girlfriend was working and wouldn't take him. His brother was in the middle of a movie and said no. Jake decided to take the bus to the store.\n",
      "Expected:\n",
      "He got what he needed all by himself.\n",
      "Output:\n",
      " He was in the middle of a movie and said no.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:12<00:54,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 17 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "I'd been looking for a stand for my TV. I looked everywhere, but the ones I saw were expensive. I happened upon a yard sale on my way home. She had a stand that was perfect, and cheap.\n",
      "Expected:\n",
      "It looks great in my den.\n",
      "Output:\n",
      " I bought it and it was perfect.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:12<00:52,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 18 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Sally had a root canal this morning, as she had a damaged root. After the procedure, the dentist wrote her a prescription. She headed straight to the pharmacy to fill her medication. She handed the prescription to the technician and waited patiently.\n",
      "Expected:\n",
      "The technician called her name and she paid for the prescription.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was so excited to get this done,\" she said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:13<00:54,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 19 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "My dog is terrified of thunder. There was a storm today. He came running into my office. He hid in the kneehole of my desk, trembling.\n",
      "Expected:\n",
      "Once the storm was over, he acted like a brave dog again.\n",
      "Output:\n",
      " I was afraid.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:14<00:53,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 20 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Mark and Jo were brainstorming ideas for a children's show. Mark suggested that a monster attacks the children. Jo laughed because he thought Mark was joking. Mark was confused because he thought it was a great idea.\n",
      "Expected:\n",
      "Mark left in a huff for having his ideas mocked.\n",
      "Output:\n",
      " Jo thought it was a great idea.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:14<00:51,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 21 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Ben's Boy Scout Troop worked for weeks on a float. It was going to be in the town's July 4th parade. They got it finished just in time. It was big enough for his whole troop to ride on.\n",
      "Expected:\n",
      "They felt proud as they went down the street as people clapped.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was like, 'Oh my God, this is going to be a big thing,'\" he says.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:15<00:49,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 22 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Francis has always wanted to learn how to tie a necktie. He decides to practice until he can tie one. At first he finds it very difficult. But eventually he is able to tie a necktie very well.\n",
      "Expected:\n",
      "Francis is proud of himself for learning how to tie a necktie.\n",
      "Output:\n",
      "\n",
      "\n",
      "The first time he tried it, he was so excited.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:16<00:50,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 23 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Eric and his wife had a daughter named Meg. Eric's wife passed away. Eric and Meg were very sad. Eric met a woman and married her 5 years after his wife died.\n",
      "Expected:\n",
      "Meg is now happy with her new stepmother.\n",
      "Output:\n",
      " He was very sad.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [00:16<00:50,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 24 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "My cousin took me to a local restaurant. We ordered a large pizza. Since she never tasted the food there, she didn't know if it was good. I began to start sneezing.\n",
      "Expected:\n",
      "To make matters worse, I caught an allergy.\n",
      "Output:\n",
      " I was so upset.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:17<00:46,  1.60it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 25 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "When I was 12 years old, my dad got angry and kicked me aggressively. Afterward, I became very ill, and tasted something metallic. I went to a doctor, and was informed that one of my kidneys was dead. Ever since, I've had swelling and hypertension.\n",
      "Expected:\n",
      "I started taking medications to combat the symptoms at 13.\n",
      "Output:\n",
      " I've had a lot of pain, and I've had a lot of pain.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:18<00:47,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 26 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Fred noticed that he feet got very hot in the summer. He decided he needed new footwear. Fred invested in a nice new pair of sandals. He loved wearing his new sandals.\n",
      "Expected:\n",
      "Fred was glad that his feet no longer got hot in the summer.\n",
      "Output:\n",
      " He was very happy with the new sandals.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:18<00:46,  1.56it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 27 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Last year I took a day trip to see a friend in Maine. I took the Amtrak from Boston to Saco, Maine. We had lunch at Gritty's in Portland. My friend drove me back to the train station.\n",
      "Expected:\n",
      "I had a nice time and will visit my friend this year.\n",
      "Output:\n",
      " I was so excited.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:19<00:46,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 28 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Heather and her family really wanted tacos for dinner. Two of the children wanted chicken tacos. The other two children wanted beef. Heather took great care preparing all the tacos that each wanted.\n",
      "Expected:\n",
      "Everyone sat down at dinner and enjoyed eating the tacos together.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was like, 'I'm going to eat this, I'm going to eat this, I'm going to eat this,'\" Heather said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:20<00:48,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 29 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Anna was filling her bird feeders. But a chunk of suet fell onto the ground. Her dog rushed over and lapped it up! Anna was astonished.\n",
      "Expected:\n",
      "She had no idea dogs loved bird food!\n",
      "Output:\n",
      " She was so excited.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:20<00:48,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 30 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "James had an Xbox 360. His friends had Xbox accounts online. James registered, but was still unable to connect online. He called for tech support, but they couldn't help either.\n",
      "Expected:\n",
      "He realized he would need a new Xbox.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was like, 'I'm not going to do this,'\" James said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:21<00:48,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 31 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "The people gathered to protest the court's ruling last week. They held signs and chanted loudly. The police stormed in and arrested them all. Now there are more protests in surrounding towns.\n",
      "Expected:\n",
      "The movement is gaining momentum!\n",
      "Output:\n",
      "\n",
      "\n",
      "The court's ruling was a victory for the protesters, who have been protesting for years.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:22<00:43,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 32 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "My roommate and I bought a new futon for our living room. The futon came in a huge box. We set the box out on the curb to be picked up on trash day. Much to our chagrin, the garbage men left the box on the curb.\n",
      "Expected:\n",
      "We had to take the box to the dump ourselves.\n",
      "Output:\n",
      " We were so upset that we called the police.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:22<00:43,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 33 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Bob chased after the rainbow through the fields. He ran after it over forests and streams. Bob thought he'd lost it behind a boulder. He found it waiting for him on the other side.\n",
      "Expected:\n",
      "When Bob dived for the pot of gold, he woke up.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm going to get you out of here,\" he said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:23<00:39,  1.65it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 34 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Soren ran through the airport, pulling her bags behind her. The female voice above her announced final boarding to Soren's fligh. She yelled for them to wait as she neared her gate, waving her arms. The attendant at the desk gave Soren a sad, sympathetic look.\n",
      "Expected:\n",
      "Nearly out of breath, Soren presented her pass and boarded the plane.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm sorry, sir,\" she said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:23<00:40,  1.58it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 35 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Charles had always wanted to have a college degree. He worked hard for many years to complete his courses. Finally he turned in his last college essay. All of his family attended his college graduation.\n",
      "Expected:\n",
      "Charles was proud that he had a college degree.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was very proud of my college degree,\" he said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [00:24<00:41,  1.54it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 36 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Stacy originally thought she wanted five kids. She and Bob first were blessed with a daughter. Two years later, they had twin girls. Now, Stacy is selling all her maternity and baby clothes.\n",
      "Expected:\n",
      "She says she has changed her mind about wanting five kids!\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm not going to be able to afford to buy a baby clothes,\" she says.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:25<00:41,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 37 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Lance was going to make a bet. He was thinking of making it a big one. He was going to bet all of his savings on a Race. The day of the Race is here.\n",
      "Expected:\n",
      "Lance crosses the finish line and Wins it all!\n",
      "Output:\n",
      " He was going to bet on a race.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:26<00:41,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 38 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Larry worked at an accounting firm. It was a boring job but it paid the bills. Larry grew tired of doing the same thing every day. He had the idea to have an office party.\n",
      "Expected:\n",
      "By lunch the whole office had passed out and nothing got done.\n",
      "Output:\n",
      " He had a friend who was a real estate agent.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:26<00:42,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 39 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Ava was six years old. She wanted to learn to swim. Her mom took her to the pool. There, she patiently taught Ava the basics.\n",
      "Expected:\n",
      "Soon Ava was paddling all by herself!\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was like, 'Oh my God, I'm going to be a swimmer,'\" she said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:27<00:42,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 40 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "James was walking down a street one afternoon. He noticed a wallet lying on the ground. He decided to bring it to the police station. That evening, the phone rang.\n",
      "Expected:\n",
      "The old man had called to thank James for returning his wallet.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was walking down the street, and I saw a man in a black hoodie, with a gun in his hand,\" he said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [00:28<00:42,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 41 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Chad's dog would always jump on people. Chad couldn't bring his dog anywhere. Chad decided to hire a dog trainer. The trainer taught the dog how to behave.\n",
      "Expected:\n",
      "Chad was proud to finally show off his dog to others.\n",
      "Output:\n",
      " Chad was so happy with the dog that he took it to the vet.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [00:28<00:38,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 42 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Karl was a good baseball player in his youth. As a middle-aged man, he joined an adult baseball team. Karl is very competitive and will do anything to win. One day, he slid into second base to beat a throw and hurt his knee.\n",
      "Expected:\n",
      "The injury made Karl realize that he wasn't young anymore.\n",
      "Output:\n",
      " He was taken to the hospital and was treated for a broken leg.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:29<00:37,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 43 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Nick was trying to buy a house. He lived with a roommate that he couldn't trust. His stuff always ended up missing from his bedroom. He knew it had to be Nick so he decided he would move out.\n",
      "Expected:\n",
      "He found a place and moved out as fast as he could.\n",
      "Output:\n",
      " He was a good guy and he was a good person.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:30<00:36,  1.51it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 44 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Jody bought a goldfish from the pet store. She noticed that the goldfish looked quite fat. Her mom told her that the goldfish had too much to eat. Jody adjusted her pet's diet.\n",
      "Expected:\n",
      "The goldfish got skinnier and healthier.\n",
      "Output:\n",
      " She ate a lot of fish, but she didn't like the taste.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:30<00:36,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 45 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Jane had recently gotten a new job. She was nervous about her first day of work. On the first day of work, Jane overslept. Jane arrived at work an hour late.\n",
      "Expected:\n",
      "Jane did not make a good impression at her new job.\n",
      "Output:\n",
      " She was exhausted.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:31<00:36,  1.46it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 46 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Jill was going on a trip to the amazon. She arrived after a flight from the US. Once there she marveled at all the beauty. It was dangerous, but exciting.\n",
      "Expected:\n",
      "Jill had a wonderful time on her trip to the Amazon.\n",
      "Output:\n",
      " She was so excited to see the world.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [00:32<00:36,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 47 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Chris is a defense attorney. He has a client that he must defend in court. The client is not guilty. Chris does his best to defend his client during his trial.\n",
      "Expected:\n",
      "Chris wins the case and the client goes free.\n",
      "Output:\n",
      " He is not a lawyer.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:33<00:36,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 48 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Julie was feeling hungry. She thought she would order some Pizza. Julie order the food through an online website. The pizza arrived and Julie tipped the driver.\n",
      "Expected:\n",
      "Julie went to take a bite of the pizza and it was burnt!\n",
      "Output:\n",
      " The driver was a man in his 20s.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:33<00:34,  1.43it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 49 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Justin was terrified of dogs. His girlfriend had a dog and he wanted to feel comfortable with it. Justin went to therapy to help him get over his fear. After a few months of therapy Justin felt better around dogs.\n",
      "Expected:\n",
      "Justin then moved in with his girlfriend and her dog.\n",
      "Output:\n",
      " He started to feel more comfortable with them.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:34<00:32,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 50 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "David was walking down the street when he felt down. He stood up and saw that his knee was bleeding. He found a handkerchief in his pants and applied it to the wound. He hopped to the nearest pharmacy stifling his pain.\n",
      "Expected:\n",
      "He then bought some peroxide and bandages to treat his knee.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm sorry, I'm sorry,\" he said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [00:35<00:32,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 51 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Nicole wanted to go to a concert in another city. Unfortunately, Nicole could not drive. She asked her cousin to take her to the concert. Her cousin agreed to drive if Naomi bought the tickets.\n",
      "Expected:\n",
      "They went to the concert and had a great time.\n",
      "Output:\n",
      " Nicole was not allowed to drive.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:35<00:31,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 52 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "I woke from my sleep at around three in the morning. I heard a scratching sound coming from inside my closet. I turned the light on beside my bed to investigate. I crept slowly toward the closet.\n",
      "Expected:\n",
      "My little brother jumped out of the closet, scaring me to death.\n",
      "Output:\n",
      " I found a small, dark room with a large, dark wall.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [00:36<00:30,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 53 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Ken put a bottle of beer in the freezer. He heard a popping noise. He looked in the freezer and saw the bottle had burst. He didn't want to wait for another beer to get cold.\n",
      "Expected:\n",
      "He drank a warm beer instead.\n",
      "Output:\n",
      " He grabbed the bottle and threw it into the freezer.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:37<00:29,  1.52it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 54 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Christmas was Tyler's favorite holiday. On Christmas morning he ran downstairs to the tree. Tyler saw so many presents and could not wait to open them. By the time his parents woke up, Tyler had opened all his presents!\n",
      "Expected:\n",
      "Tyler showed his parents everything Santa Claus gave him.\n",
      "Output:\n",
      "\n",
      "\n",
      "Tyler's parents were very excited about Christmas.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [00:37<00:28,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 55 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Wendy was working at her local fast food establishment. She pretty much hated her Job. Wendy was having a rough day and her employees were annoying her. The cook decided to defy her orders when she said go clean the trash.\n",
      "Expected:\n",
      "Wendy flew off the handle and fired him on the spot.\n",
      "Output:\n",
      " Wendy was so upset that she went to the bathroom and cleaned up the trash.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [00:38<00:27,  1.57it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 56 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Walter was worried because his dog was showing a lot of aggression. The dog recently began snapping at other dogs and even people. Walter consulted with his veterinarian. The vet discovered that the dog was suffering a flea infestation.\n",
      "Expected:\n",
      "Some medication got rid of the fleas and the dog's bad mood, too.\n",
      "Output:\n",
      " Walter was concerned that the flea was spreading to other dogs.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [00:38<00:27,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 57 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "The couple took a romantic trip to the lake. They stayed in a nice cabin by the water. They went boating and relaxed in the hammock. They were happy to reconnect with each other.\n",
      "Expected:\n",
      "When they returned home, they decided to buy a lake house.\n",
      "Output:\n",
      "\n",
      "\n",
      "The couple had a great time.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:39<00:27,  1.48it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 58 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "The family planned their first trip to Universal Studios. They were excited to go on all the rides. They saw a lot of the characters. They spent three days in the park.\n",
      "Expected:\n",
      "They were sad to come home.\n",
      "Output:\n",
      " They were very excited.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:40<00:29,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 59 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "I went to a restaurant. I ordered fries. They put ketchup on the fries. I was furious at the awful site.\n",
      "Expected:\n",
      "After complaining, I was given delicious, ketchup free fries.\n",
      "Output:\n",
      " I was so angry.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:41<00:28,  1.39it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 60 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "The woman decided to start a new hobby. She went to the craft store and picked out some supplies. She went home and created an amazing masterpiece. She was very proud of her work.\n",
      "Expected:\n",
      "She displayed it in her kitchen.\n",
      "Output:\n",
      " She was very happy with the results.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:41<00:26,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 61 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "James had always wanted to try out for a sport at his school. He decided he would try out for football. James exercised every day to be ready to try out. After trying out, James was accepted onto the team.\n",
      "Expected:\n",
      "James was glad to be playing a sport at school.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I was really excited to try out for the first time.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [00:42<00:24,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 62 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Josie wanted to win an important race at school. She woke up early for a week to practice in the park. She also hired a coach to train with him after school. When the race event started she was really nervous.\n",
      "Expected:\n",
      "But all her hard work paid off and she made it to third place easily.\n",
      "Output:\n",
      " She was worried about her health.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [00:43<00:22,  1.57it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 63 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Kayla parked her car in front of the convenience store. She got out of the car, and began to walk towards the store. Suddenly, she got hit in the head with an egg. She looked up and saw teenagers on top of the store.\n",
      "Expected:\n",
      "The teenagers ran away, and Kayla was left with an egg on her head.\n",
      "Output:\n",
      " She ran to the back of the store and grabbed the egg.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [00:43<00:22,  1.55it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 64 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "A police officer got a new patrol route. He wasn't familiar with the neighborhood. He spent a lot of time familiarizing himself with the street names. SOon he got to know everyone in the neighborhood.\n",
      "Expected:\n",
      "He was beginning to feel at home.\n",
      "Output:\n",
      " He was able to get a sense of the neighborhood.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [00:44<00:21,  1.61it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 65 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Mikey has a habit of taking items that don't belong to him. Last night he stole a trailer from Henry's yard. Henry has a camera in his yard and caught Mikey on tape. The cops were called and took Mikey to jail.\n",
      "Expected:\n",
      "Mikey is now sitting in a cell thinking about his actions.\n",
      "Output:\n",
      "\n",
      "\n",
      "The video shows Mikey walking out of the house and into the yard.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [00:45<00:23,  1.41it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 66 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Roger was hungry. He checked the fridge. The fridge was empty. Roger went to the store.\n",
      "Expected:\n",
      "He came home with lots of food.\n",
      "Output:\n",
      " He bought a bag of chips.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:45<00:21,  1.49it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 67 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Bob stared in disbelief at the flooded basement. All that could be seen were the stone arches above the doors. The plumber told him it flooded because the sump pump was off. Bob understood that was because the electricity had also been off.\n",
      "Expected:\n",
      "He enabled the electricity and the pump drained the flooded basement.\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm sorry, but I'm not going to let you go,\" he said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [00:46<00:20,  1.50it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 68 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Oscar decided that he no longer wanted to be out of shape. He decided to start running outside every day. At first he found it very difficult. However, over time, Oscar began to enjoy running.\n",
      "Expected:\n",
      "He was glad to be getting in shape.\n",
      "Output:\n",
      " He started to feel more comfortable and more confident.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [00:47<00:19,  1.53it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 69 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Jill went to the doctor for her annual exam. A lump was found on her breast and she needed more testing. She went to a follow up appointment and it was confirmed as cancer. Jill went through several rounds of chemotherapy.\n",
      "Expected:\n",
      "Fortunately, she had no signs of cancer following her treatment.\n",
      "Output:\n",
      " She was told she was going to have to undergo a second round of chemotherapy.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:47<00:20,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 70 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Jasmine had homework to do. She did not have a pencil. She looked around the room for one. The room did not have a pencil.\n",
      "Expected:\n",
      "Jasmine decided not to do her homework.\n",
      "Output:\n",
      " She looked around the room for one.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:48<00:20,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 71 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Marc always had perfect attendance at school. One day, he stopped coming to class. Everyone was worried about him! He came back a few days later.\n",
      "Expected:\n",
      "He had been in bed with the flu.\n",
      "Output:\n",
      " He was a little nervous.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [00:49<00:19,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 72 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Joe was really excited for Christmas. Joe has never seen Santa Claus before. He decided to hide on top of the staircase to try to catch Santa. Joe waited as long as he could before he fell asleep.\n",
      "Expected:\n",
      "He woke up to many presents under the tree, and no Santa in sight!\n",
      "Output:\n",
      "\n",
      "\n",
      "Joe woke up to find Santa Claus in his room.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [00:49<00:18,  1.42it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 73 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Anna went to pick apples. She tried to pluck the low-hanging fruits. But she could reach very few. At the end of the trip, she had only ten apples.\n",
      "Expected:\n",
      "Anna wished she had been able to reach more apples!\n",
      "Output:\n",
      "\n",
      "\n",
      "\"I'm sorry, but I'm not going to eat them,\" she said.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:50<00:16,  1.47it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 74 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Bob bought a new manufactured home in Montana. He was sad he didn't have any land to grow a garden on. One of his neighbors told him he could vegetables in tires. Bob tried it and was astounded when it worked.\n",
      "Expected:\n",
      "He's very proud of his tire grown tomatoes and corn.\n",
      "Output:\n",
      " He bought a new home in Montana.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [00:51<00:17,  1.40it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 75 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "The candidates were running a tight campaign. The latest poll said they were tied. The Republican candidate focused on radio ads. The Democrat focused on TV.\n",
      "Expected:\n",
      "They fought for every vote they could grab.\n",
      "Output:\n",
      "\n",
      "\n",
      "The poll was conducted by telephone from Oct.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:52<00:15,  1.44it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case 76 :\n",
      "----------------------------------------------------------------------------------------------------\n",
      "input:\n",
      "Johnnie got dragged to the ballet because his sister wanted to go. He was dreading how boring it would be. He was already bored when the lights were dimmed. Then when the dancers started he got into it.\n",
      "Expected:\n",
      "He was sad when it ended.\n",
      "Output:\n",
      " He was so excited.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:52<00:15,  1.46it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8478188a121c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mlen_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#output = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpred_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mexpected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    # Story is:\n",
    "    input_ids = tokenizer(data.input.iloc[i], return_tensors='pt')\n",
    "    input_ids.to(device)\n",
    "    \n",
    "    greedy_output = model.generate(**input_ids, return_dict_in_generate=True, output_scores=True, max_length=100)\n",
    "    output = tokenizer.decode(greedy_output['sequences'][0])\n",
    "    len_input = len(data.input.iloc[i])\n",
    "    #output = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    pred_sent = output[len_input:output.index('.',len_input)+1]\n",
    "    expected = data.sentence5.iloc[i]\n",
    "    \n",
    "    print('case',  i ,':\\n' + 100 * '-')\n",
    "    print('input:')\n",
    "    print(data.input.iloc[i])\n",
    "    print(\"Expected:\")\n",
    "    print(expected)\n",
    "    print(\"Output:\")\n",
    "    print(pred_sent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to convert output to TensorFlow tensors format, TensorFlow is not installed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_16053/2314891936.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# encode context the generation is conditioned on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I enjoy walking with my cute dog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;31m# generate text until the output length (which includes the context length) reaches 50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mgreedy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpt22/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, return_tensors, **kwargs)\u001b[0m\n\u001b[1;32m   2164\u001b[0m                 ``convert_tokens_to_ids`` method).\n\u001b[1;32m   2165\u001b[0m         \"\"\"\n\u001b[0;32m-> 2166\u001b[0;31m         encoded_inputs = self.encode_plus(\n\u001b[0m\u001b[1;32m   2167\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpt22/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2491\u001b[0m         )\n\u001b[1;32m   2492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2493\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2494\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpt22/lib/python3.9/site-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0msecond_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         return self.prepare_for_model(\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mfirst_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0mpair_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msecond_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpt22/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mprepare_for_model\u001b[0;34m(self, ids, pair_ids, add_special_tokens, padding, truncation, max_length, stride, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, prepend_batch_axis, **kwargs)\u001b[0m\n\u001b[1;32m   2965\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2967\u001b[0;31m         batch_outputs = BatchEncoding(\n\u001b[0m\u001b[1;32m   2968\u001b[0m             \u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m         )\n",
      "\u001b[0;32m~/miniconda3/envs/gpt22/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpt22/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtensor_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTENSORFLOW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m    669\u001b[0m                     \u001b[0;34m\"Unable to convert output to TensorFlow tensors format, TensorFlow is not installed.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                 )\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to convert output to TensorFlow tensors format, TensorFlow is not installed."
     ]
    }
   ],
   "source": [
    "#tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "\n",
    "# add the EOS token as PAD token to avoid warnings\n",
    "#model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "#device = torch.device('cuda:0')\n",
    "#model.to(device)\n",
    "\n",
    "#model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "#device_map = {0: [0, 1, 2],\n",
    "#            1: [3, 4,5],\n",
    "#            2: [6, 7, 8],\n",
    "#            3: [9,10,11]}\n",
    "#model.parallelize(device_map) # Splits the model across several devices\n",
    "\n",
    "\n",
    "# encode context the generation is conditioned on\n",
    "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='tf')\n",
    "# generate text until the output length (which includes the context length) reaches 50\n",
    "greedy_output = model.generate(input_ids, max_length=50)\n",
    "print(\"Output:\\n\" + 100 * '-')\n",
    "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(100)):\n",
    "    # Story is:\n",
    "    input_ids = tokenizer.encode(data.input.iloc[i], return_tensors='tf')\n",
    "    \n",
    "    greedy_output = model.generate(input_ids, max_length=100)\n",
    "    len_input = len(data.input.iloc[i])\n",
    "    output = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    pred_sent = output[len_input:output.index('.',len_input)+1]\n",
    "    expected = data.sentence5.iloc[i]\n",
    "    \n",
    "    print('case',  i ,':\\n' + 100 * '-')\n",
    "    print('input:')\n",
    "    print(data.input.iloc[i])\n",
    "    print(\"Expected:\")\n",
    "    print(expected)\n",
    "    print(\"Output:\")\n",
    "    print(pred_sent)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt23",
   "language": "python",
   "name": "gpt23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
